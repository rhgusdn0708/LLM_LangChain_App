{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d3b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57437832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 모델 설정\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# 첫 번째 AI 에이전트: 질문 분석 및 배경 정보 생성\n",
    "def agent_1(state):\n",
    "    \"\"\"사용자의 질문을 분석하고 핵심 키워드와 배경 정보를 추가\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # 질문에서 핵심 키워드 추출\n",
    "    keywords = llm.invoke(f\"질문: {query}\\n이 질문에서 핵심 키워드를 3~5개 추출해 주세요.\")\n",
    "    \n",
    "    # 질문과 관련된 배경 정보 제공\n",
    "    background_info = llm.invoke(f\"질문: {query}\\n이 질문을 이해하는 데 도움이 될 만한 추가 정보를 제공해 주세요.\")\n",
    "\n",
    "    print(f\"\\n[Agent 1] 원본 질문: {query}\")\n",
    "    print(f\"[Agent 1] 핵심 키워드: {keywords}\")\n",
    "    print(f\"[Agent 1] 배경 정보: {background_info}\\n\")\n",
    "\n",
    "    return {\"refined_query\": query, \"keywords\": keywords, \"background_info\": background_info}\n",
    "\n",
    "# 두 번째 AI 에이전트: 키워드 및 배경 정보를 활용하여 답변 생성\n",
    "def agent_2(state):\n",
    "    \"\"\"Agent 1이 제공한 정보를 기반으로 보다 정교한 답변 생성\"\"\"\n",
    "    refined_query = state[\"refined_query\"]\n",
    "    keywords = state[\"keywords\"]\n",
    "    background_info = state[\"background_info\"]\n",
    "\n",
    "    # Agent 1이 제공한 정보를 활용하여 최종 답변 생성\n",
    "    final_response = llm.invoke(\n",
    "        f\"질문: {refined_query}\\n\"\n",
    "        f\"핵심 키워드: {keywords}\\n\"\n",
    "        f\"배경 정보: {background_info}\\n\"\n",
    "        f\"위 정보를 바탕으로 질문에 대해 깊이 있는 답변을 작성해 주세요.\"\n",
    "    )\n",
    "\n",
    "    print(f\"[Agent 2] 최종 답변 생성 완료\\n\")\n",
    "    \n",
    "    return {\"final_answer\": final_response}\n",
    "\n",
    "# LangGraph Workflow 설정\n",
    "workflow = StateGraph(dict)  \n",
    "\n",
    "# 그래프의 시작점 정의\n",
    "workflow.add_node(\"agent_1\", agent_1)\n",
    "workflow.add_node(\"agent_2\", agent_2)\n",
    "\n",
    "# 실행 흐름(Edges) 정의\n",
    "workflow.set_entry_point(\"agent_1\")  # Agent 1이 먼저 실행됨\n",
    "workflow.add_edge(\"agent_1\", \"agent_2\")  # Agent 1 -> Agent 2\n",
    "\n",
    "# 실행 엔진 빌드\n",
    "app = workflow.compile()\n",
    "\n",
    "# 실행 예제\n",
    "query = \"LangGraph는 무엇이며, LangChain과 어떤 차이점이 있나요? 그리고 LangGraph를 사용해야 하는 이유는 무엇인가요?\"\n",
    "state = {\"query\": query}\n",
    "result = app.invoke(state)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(\"\\n🔹 [AI 최종 답변]:\")\n",
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)        \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4da5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 17:03:37.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    pip install -U langchain langchain-core langchain-commnity langchain-experimental langchain-huggingface langchain-ollama\n",
    "    pip install streamlit --upgrade\n",
    "    pip install sentence-transformers\n",
    "    pip install pdfplumber faiss-cpu pydantic\n",
    "'''\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# 색상 팔레트 정의\n",
    "primary_color = \"#1E90FF\"  # 기본 색상\n",
    "secondary_color = \"#FF6347\"  # 보조 색상\n",
    "background_color = \"#F5F5F5\"  # 배경 색상\n",
    "text_color = \"#4561e9\"  # 텍스트 색상\n",
    "\n",
    "# 사용자 정의 CSS 적용\n",
    "st.markdown(f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-color: {background_color};\n",
    "        color: {text_color};\n",
    "    }}\n",
    "    .stButton>button {{\n",
    "        background-color: {primary_color};\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    .stTextInput>div>div>input {{\n",
    "        border: 2px solid {primary_color};\n",
    "        border-radius: 5px;\n",
    "        padding: 10px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    .stFileUploader>div>div>div>button {{\n",
    "        background-color: {secondary_color};\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Streamlit 앱 제목 설정\n",
    "st.title(\"Ollama 기반 RAG 시스템 구축\")\n",
    "\n",
    "# PDF 파일 업로드\n",
    "uploaded_file = st.file_uploader(\"PDF 파일을 업로드하세요\", type=\"pdf\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # 업로드된 파일을 임시 위치에 저장\n",
    "    with open(\"temp.pdf\", \"wb\") as f:\n",
    "        f.write(uploaded_file.getvalue())\n",
    "\n",
    "    # PDF 로더 초기화\n",
    "    loader = PDFPlumberLoader(\"temp.pdf\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # 문서 분할기 초기화\n",
    "    text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    # 임베딩 모델 초기화\n",
    "    embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "    # 벡터 스토어 생성 및 임베딩 추가\n",
    "    vector = FAISS.from_documents(documents, embedder)\n",
    "    retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "    # LLM 정의\n",
    "    llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "    #llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "    # # 시스템 프롬프트 정의\n",
    "    # system_prompt = (\n",
    "    # \"주어진 문맥을 참고하여 질문에 답하세요. \"\n",
    "    # \"답을 모를 경우, '모르겠습니다'라고만 답하고 스스로 답을 만들지 마세요. \"\n",
    "    # \"답변은 최대 3문장으로 간결하게 작성하세요. \"\n",
    "    # \"최종 답변은 무조건 한국어(korean)으로 작성해주세요\"\n",
    "    # \"문맥: {context}\"\n",
    "    # )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Answer the question with reference to the given context.\"\n",
    "        \"If you don't know the answer, just say 'I don't know' and don't make up your own answer.\"\n",
    "        \"Please write your answer concisely, with a maximum of 3 sentences.\"\n",
    "        \"Please write your final answer in Korean (Korean) without fail.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "\n",
    "    # ChatPromptTemplate 정의\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 문서 결합 체인 생성\n",
    "    combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    # 검색 기반 QA 체인 생성\n",
    "    rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "    # 사용자 입력 받기\n",
    "    user_input = st.text_input(\"PDF와 관련된 질문을 입력하세요:\")\n",
    "\n",
    "    # 사용자 입력 처리\n",
    "    if user_input:\n",
    "        with st.spinner(\"처리 중...\"):\n",
    "            response = rag_chain.invoke({\"input\": user_input})\n",
    "            st.write(\"응답:\")\n",
    "            st.write(response.get(\"answer\",\"응답을 처리할 수 없습니다.\"))\n",
    "else:\n",
    "    st.write(\"진행하려면 PDF 파일을 업로드하세요.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
