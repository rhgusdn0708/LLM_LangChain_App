{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d3b91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57437832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ AI ì—ì´ì „íŠ¸: ì§ˆë¬¸ ë¶„ì„ ë° ë°°ê²½ ì •ë³´ ìƒì„±\n",
    "def agent_1(state):\n",
    "    \"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œì™€ ë°°ê²½ ì •ë³´ë¥¼ ì¶”ê°€\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "    keywords = llm.invoke(f\"ì§ˆë¬¸: {query}\\nì´ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 3~5ê°œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    # ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë°°ê²½ ì •ë³´ ì œê³µ\n",
    "    background_info = llm.invoke(f\"ì§ˆë¬¸: {query}\\nì´ ì§ˆë¬¸ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ë§Œí•œ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "    print(f\"\\n[Agent 1] ì›ë³¸ ì§ˆë¬¸: {query}\")\n",
    "    print(f\"[Agent 1] í•µì‹¬ í‚¤ì›Œë“œ: {keywords}\")\n",
    "    print(f\"[Agent 1] ë°°ê²½ ì •ë³´: {background_info}\\n\")\n",
    "\n",
    "    return {\"refined_query\": query, \"keywords\": keywords, \"background_info\": background_info}\n",
    "\n",
    "# ë‘ ë²ˆì§¸ AI ì—ì´ì „íŠ¸: í‚¤ì›Œë“œ ë° ë°°ê²½ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "def agent_2(state):\n",
    "    \"\"\"Agent 1ì´ ì œê³µí•œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³´ë‹¤ ì •êµí•œ ë‹µë³€ ìƒì„±\"\"\"\n",
    "    refined_query = state[\"refined_query\"]\n",
    "    keywords = state[\"keywords\"]\n",
    "    background_info = state[\"background_info\"]\n",
    "\n",
    "    # Agent 1ì´ ì œê³µí•œ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "    final_response = llm.invoke(\n",
    "        f\"ì§ˆë¬¸: {refined_query}\\n\"\n",
    "        f\"í•µì‹¬ í‚¤ì›Œë“œ: {keywords}\\n\"\n",
    "        f\"ë°°ê²½ ì •ë³´: {background_info}\\n\"\n",
    "        f\"ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "    print(f\"[Agent 2] ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ\\n\")\n",
    "    \n",
    "    return {\"final_answer\": final_response}\n",
    "\n",
    "# LangGraph Workflow ì„¤ì •\n",
    "workflow = StateGraph(dict)  \n",
    "\n",
    "# ê·¸ë˜í”„ì˜ ì‹œì‘ì  ì •ì˜\n",
    "workflow.add_node(\"agent_1\", agent_1)\n",
    "workflow.add_node(\"agent_2\", agent_2)\n",
    "\n",
    "# ì‹¤í–‰ íë¦„(Edges) ì •ì˜\n",
    "workflow.set_entry_point(\"agent_1\")  # Agent 1ì´ ë¨¼ì € ì‹¤í–‰ë¨\n",
    "workflow.add_edge(\"agent_1\", \"agent_2\")  # Agent 1 -> Agent 2\n",
    "\n",
    "# ì‹¤í–‰ ì—”ì§„ ë¹Œë“œ\n",
    "app = workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì œ\n",
    "query = \"LangGraphëŠ” ë¬´ì—‡ì´ë©°, LangChainê³¼ ì–´ë–¤ ì°¨ì´ì ì´ ìˆë‚˜ìš”? ê·¸ë¦¬ê³  LangGraphë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "state = {\"query\": query}\n",
    "result = app.invoke(state)\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ”¹ [AI ìµœì¢… ë‹µë³€]:\")\n",
    "print(result[\"final_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)        \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4da5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 17:03:37.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 17:03:37.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    pip install -U langchain langchain-core langchain-commnity langchain-experimental langchain-huggingface langchain-ollama\n",
    "    pip install streamlit --upgrade\n",
    "    pip install sentence-transformers\n",
    "    pip install pdfplumber faiss-cpu pydantic\n",
    "'''\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì •ì˜\n",
    "primary_color = \"#1E90FF\"  # ê¸°ë³¸ ìƒ‰ìƒ\n",
    "secondary_color = \"#FF6347\"  # ë³´ì¡° ìƒ‰ìƒ\n",
    "background_color = \"#F5F5F5\"  # ë°°ê²½ ìƒ‰ìƒ\n",
    "text_color = \"#4561e9\"  # í…ìŠ¤íŠ¸ ìƒ‰ìƒ\n",
    "\n",
    "# ì‚¬ìš©ì ì •ì˜ CSS ì ìš©\n",
    "st.markdown(f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-color: {background_color};\n",
    "        color: {text_color};\n",
    "    }}\n",
    "    .stButton>button {{\n",
    "        background-color: {primary_color};\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    .stTextInput>div>div>input {{\n",
    "        border: 2px solid {primary_color};\n",
    "        border-radius: 5px;\n",
    "        padding: 10px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    .stFileUploader>div>div>div>button {{\n",
    "        background-color: {secondary_color};\n",
    "        color: white;\n",
    "        border-radius: 5px;\n",
    "        border: none;\n",
    "        padding: 10px 20px;\n",
    "        font-size: 16px;\n",
    "    }}\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Streamlit ì•± ì œëª© ì„¤ì •\n",
    "st.title(\"Ollama ê¸°ë°˜ RAG ì‹œìŠ¤í…œ êµ¬ì¶•\")\n",
    "\n",
    "# PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "uploaded_file = st.file_uploader(\"PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”\", type=\"pdf\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ìœ„ì¹˜ì— ì €ì¥\n",
    "    with open(\"temp.pdf\", \"wb\") as f:\n",
    "        f.write(uploaded_file.getvalue())\n",
    "\n",
    "    # PDF ë¡œë” ì´ˆê¸°í™”\n",
    "    loader = PDFPlumberLoader(\"temp.pdf\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    # ë¬¸ì„œ ë¶„í• ê¸° ì´ˆê¸°í™”\n",
    "    text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    embedder = HuggingFaceEmbeddings()\n",
    "\n",
    "    # ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ì„ë² ë”© ì¶”ê°€\n",
    "    vector = FAISS.from_documents(documents, embedder)\n",
    "    retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "    # LLM ì •ì˜\n",
    "    llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "    #llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "    # # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    # system_prompt = (\n",
    "    # \"ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”. \"\n",
    "    # \"ë‹µì„ ëª¨ë¥¼ ê²½ìš°, 'ëª¨ë¥´ê² ìŠµë‹ˆë‹¤'ë¼ê³ ë§Œ ë‹µí•˜ê³  ìŠ¤ìŠ¤ë¡œ ë‹µì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. \"\n",
    "    # \"ë‹µë³€ì€ ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. \"\n",
    "    # \"ìµœì¢… ë‹µë³€ì€ ë¬´ì¡°ê±´ í•œêµ­ì–´(korean)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”\"\n",
    "    # \"ë¬¸ë§¥: {context}\"\n",
    "    # )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Answer the question with reference to the given context.\"\n",
    "        \"If you don't know the answer, just say 'I don't know' and don't make up your own answer.\"\n",
    "        \"Please write your answer concisely, with a maximum of 3 sentences.\"\n",
    "        \"Please write your final answer in Korean (Korean) without fail.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "\n",
    "    # ChatPromptTemplate ì •ì˜\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ë¬¸ì„œ ê²°í•© ì²´ì¸ ìƒì„±\n",
    "    combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    # ê²€ìƒ‰ ê¸°ë°˜ QA ì²´ì¸ ìƒì„±\n",
    "    rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°\n",
    "    user_input = st.text_input(\"PDFì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:\")\n",
    "\n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "    if user_input:\n",
    "        with st.spinner(\"ì²˜ë¦¬ ì¤‘...\"):\n",
    "            response = rag_chain.invoke({\"input\": user_input})\n",
    "            st.write(\"ì‘ë‹µ:\")\n",
    "            st.write(response.get(\"answer\",\"ì‘ë‹µì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"))\n",
    "else:\n",
    "    st.write(\"ì§„í–‰í•˜ë ¤ë©´ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
