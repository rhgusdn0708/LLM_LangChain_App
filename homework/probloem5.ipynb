{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbce5a03",
   "metadata": {},
   "source": [
    "### 5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e56483e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "import re\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5f1a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./db/cafe_db' ê²½ë¡œì—ì„œ FAISS ë²¡í„° DB ë¡œë“œ ì¤‘...\n",
      "FAISS ë²¡í„° DB ë¡œë“œ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "def load_vector_db(db_path=\"./db/cafe_db\"):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"'{db_path}' ê²½ë¡œì—ì„œ FAISS ë²¡í„° DB ë¡œë“œ ì¤‘...\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS ë²¡í„° DB ë¡œë“œ ì™„ë£Œ.\")\n",
    "    return vectorstore\n",
    "\n",
    "# ë²¡í„° DB ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ (ì „ì—­ì ìœ¼ë¡œ ì‚¬ìš©)\n",
    "cafe_vector_db = load_vector_db()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ec619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ì¹´í˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥) ---\n",
      "\n",
      "[ì‚¬ìš©ì ì§ˆë¬¸]: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ì€ ì–¼ë§ˆì•¼?\n",
      "\n",
      "[Tool Call Detected]: [{'name': 'db_search_cafe_func', 'args': {'query': 'ì•„ë©”ë¦¬ì¹´ë…¸ ê°€ê²©'}, 'id': 'call_3lNCQyZVz9niH7jAJYQJZHJx', 'type': 'tool_call'}]\n",
      "Calling DB search tool with query: ì•„ë©”ë¦¬ì¹´ë…¸ ê°€ê²©\n",
      "[AI ë‹µë³€]: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ì€ â‚©4,500ì…ë‹ˆë‹¤. ì´ ìŒë£ŒëŠ” ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ëœ¨ê±°ìš´ ë¬¼ì„ ë”í•´ ë§Œë“  í´ë˜ì‹í•œ ë¸”ë™ ì»¤í”¼ë¡œ, ì›ë‘ ë³¸ì—°ì˜ ë§›ì„ ì˜ ëŠë‚„ ìˆ˜ ìˆìœ¼ë©° ê¹”ë”í•˜ê³  ê¹Šì€ í’ë¯¸ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ ì„¤íƒ•ì´ë‚˜ ì‹œëŸ½ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ì‚¬ìš©ì ì§ˆë¬¸]: ê³ ë§ˆì›Œ ë!\n",
      "[AI ë‹µë³€]: ì²œë§Œì—ìš”! ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸ˜Š\n",
      "AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
      "\n",
      "--- AI ì–´ì‹œìŠ¤í„´íŠ¸ ì¢…ë£Œ ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. ë„êµ¬ ì •ì˜\n",
    "\n",
    "# a) tavily_search_func\n",
    "tavily_search_tool = TavilySearchResults()\n",
    "\n",
    "# b) wiki_summary\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì¼ë°˜ ì§€ì‹ ê²€ìƒ‰ ë° ìš”ì•½.\n",
    "    ì…ë ¥: ê²€ìƒ‰ ì£¼ì œ (str)\n",
    "    ì¶œë ¥: ìš”ì•½ëœ ì •ë³´ (str)\n",
    "    \"\"\"\n",
    "    print(f\"Calling Wikipedia tool with query: {query}\")\n",
    "    try:\n",
    "        summary = wikipedia_wrapper.run(query)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "\n",
    "# c) db_search_cafe_func\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ë¡œì»¬ ì¹´í˜ ë©”ë‰´ DBì—ì„œ ë©”ë‰´ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰.\n",
    "    ì…ë ¥: ë©”ë‰´ ê´€ë ¨ ì¿¼ë¦¬ (str)\n",
    "    ì¶œë ¥: ê´€ë ¨ ë©”ë‰´ ì •ë³´ (str)\n",
    "    ì‚¬ìš© ì˜ˆ: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©, ì¬ë£Œ, íŠ¹ì§• ë“±\n",
    "    \"\"\"\n",
    "    print(f\"Calling DB search tool with query: {query}\")\n",
    "    docs = cafe_vector_db.similarity_search(query, k=1) # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 1ê°œ ê²€ìƒ‰\n",
    "    if docs:\n",
    "        # Document ê°ì²´ì˜ page_contentë¥¼ ë°˜í™˜\n",
    "        return docs[0].page_content\n",
    "    return \"í•´ë‹¹ ë©”ë‰´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ëª¨ë“  ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "tools = [tavily_search_tool, wiki_summary, db_search_cafe_func]\n",
    "\n",
    "# 3. LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# 4. í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "system_prompt_content = (\n",
    "    \"ë‹¹ì‹ ì€ ì¹´í˜ ë©”ë‰´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í•„ìš”ì‹œ ì›¹ ê²€ìƒ‰ì´ë‚˜ ìœ„í‚¤í”¼ë””ì•„ë¥¼ í™œìš©í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "    \"ë©”ë‰´ ì •ë³´ëŠ” 'db_search_cafe_func' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³ , ì¼ë°˜ì ì¸ ì§€ì‹ì€ 'wiki_summary'ë¥¼, ìµœì‹  ì •ë³´ë‚˜ ì›¹ ê²€ìƒ‰ì€ 'tavily_search_func'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_content),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. LLMì— ë„êµ¬ ë°”ì¸ë”©\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "# 6. ê°„ë‹¨í•œ ë„êµ¬ í˜¸ì¶œ ì²´ì¸ êµ¬í˜„\n",
    "@chain\n",
    "def tool_calling_chain(input_data: dict):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ LLMì´ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•˜ë©°, ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì²´ì¸.\n",
    "    \"\"\"\n",
    "    query = input_data[\"input\"]\n",
    "    chat_history = input_data.get(\"chat_history\", [])\n",
    "    \n",
    "    agent_scratchpad = [] \n",
    "\n",
    "    prompt_values = {\n",
    "        \"input\": query,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"agent_scratchpad\": agent_scratchpad\n",
    "    }\n",
    "    \n",
    "    full_prompt_message = prompt.invoke(prompt_values)\n",
    "    \n",
    "    ai_message = agent_llm.invoke(full_prompt_message)\n",
    "    \n",
    "    # Step 2: ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ í™•ì¸ ë° ì‹¤í–‰\n",
    "    # ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤: tool_call_dictë¡œ ì ‘ê·¼í•˜ë„ë¡ ë³€ê²½\n",
    "    if ai_message.tool_calls:\n",
    "        print(f\"\\n[Tool Call Detected]: {ai_message.tool_calls}\")\n",
    "        tool_results = []\n",
    "        for tool_call_dict in ai_message.tool_calls: # tool_call_dictë¡œ ì´ë¦„ ë³€ê²½\n",
    "            # dict ê°ì²´ì—ì„œ 'name', 'args', 'id' í‚¤ë¡œ ì ‘ê·¼\n",
    "            tool_name = tool_call_dict.get('name') \n",
    "            tool_args = tool_call_dict.get('args')\n",
    "            tool_id = tool_call_dict.get('id')\n",
    "\n",
    "            if not tool_name: # 'name' í‚¤ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„ (ì˜ˆì™¸ ì²˜ë¦¬)\n",
    "                print(f\"Warning: Tool call dictionary missing 'name' key: {tool_call_dict}. Skipping this tool call.\")\n",
    "                continue\n",
    "\n",
    "            result = None\n",
    "            try:\n",
    "                if tool_name == tavily_search_tool.name:\n",
    "                    # tool_argsê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ .get('query') í˜¸ì¶œ ì‹œ ê¸°ë³¸ê°’ ì§€ì •\n",
    "                    result = tavily_search_tool.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == wiki_summary.name:\n",
    "                    result = wiki_summary.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == db_search_cafe_func.name:\n",
    "                    result = db_search_cafe_func.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                else:\n",
    "                    result = f\"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}\"\n",
    "            except Exception as e:\n",
    "                result = f\"ë„êµ¬ {tool_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "            \n",
    "            # ToolMessage ìƒì„± ì‹œ tool_idë¥¼ ì „ë‹¬\n",
    "            tool_results.append(ToolMessage(content=str(result), tool_call_id=tool_id))\n",
    "        \n",
    "        # Step 3: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ LLM ì¬í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "        updated_agent_scratchpad = [ai_message] + tool_results\n",
    "\n",
    "        re_invoke_prompt_values = {\n",
    "            \"input\": query,\n",
    "            \"chat_history\": chat_history,\n",
    "            \"agent_scratchpad\": updated_agent_scratchpad\n",
    "        }\n",
    "        \n",
    "        re_invoke_full_prompt_message = prompt.invoke(re_invoke_prompt_values)\n",
    "        \n",
    "        final_response_message = agent_llm.invoke(re_invoke_full_prompt_message)\n",
    "        return final_response_message.content\n",
    "    else:\n",
    "        # ë„êµ¬ í˜¸ì¶œì´ ì—†ëŠ” ê²½ìš° LLMì˜ ì›ë˜ ë‹µë³€ ë°˜í™˜\n",
    "        return ai_message.content\n",
    "\n",
    "# 7. ì„¸ì…˜ ê¸°ë¡ ê´€ë¦¬ ë° RunnableWithMessageHistory ë°”ì¸ë”©\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    tool_calling_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 8. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- ì¹´í˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥) ---\")\n",
    "\n",
    "    # ì„¸ì…˜ IDë¥¼ í•˜ë‚˜ë¡œ ìœ ì§€í•˜ì—¬ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í™œìš©í•˜ë„ë¡ ì„¤ì • (ì„ íƒ ì‚¬í•­)\n",
    "    session_id = \"user_session_123\" \n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\në‹¹ì‹ ì˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"ì¢…ë£Œ\"]:\n",
    "            print(\"AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n[ì‚¬ìš©ì ì§ˆë¬¸]: {user_input}\")\n",
    "        \n",
    "        try:\n",
    "            response = conversational_chain.invoke(\n",
    "                {\"input\": user_input},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            print(f\"[AI ë‹µë³€]: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ì˜¤ë¥˜ ë°œìƒ]: {e}\")\n",
    "            print(\"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ì§ˆë¬¸ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\")\n",
    "            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë£¨í”„ë¥¼ ì¢…ë£Œí•˜ê±°ë‚˜ ê³„ì† ì§„í–‰í• ì§€ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            # ì—¬ê¸°ì„œëŠ” ì˜¤ë¥˜ê°€ ë‚˜ë”ë¼ë„ ê³„ì† ì§ˆë¬¸ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ breakë¥¼ ì œê±°í•©ë‹ˆë‹¤.\n",
    "\n",
    "    print(\"\\n--- AI ì–´ì‹œìŠ¤í„´íŠ¸ ì¢…ë£Œ ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d9259",
   "metadata": {},
   "source": [
    "### 5-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71a56b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "import re\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79aa73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./db/cafe_db' ê²½ë¡œì—ì„œ FAISS ë²¡í„° DB ë¡œë“œ ì¤‘...\n",
      "FAISS ë²¡í„° DB ë¡œë“œ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "def load_vector_db(db_path=\"./db/cafe_db\"):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"'{db_path}' ê²½ë¡œì—ì„œ FAISS ë²¡í„° DB ë¡œë“œ ì¤‘...\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS ë²¡í„° DB ë¡œë“œ ì™„ë£Œ.\")\n",
    "    return vectorstore\n",
    "\n",
    "# ë²¡í„° DB ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ (ì „ì—­ì ìœ¼ë¡œ ì‚¬ìš©)\n",
    "cafe_vector_db = load_vector_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f799f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ì¹´í˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥) ---\n",
      "\n",
      "[Tool Call Detected]: [{'name': 'wiki_summary', 'args': {'query': 'ë¼ë–¼ì˜ ì—­ì‚¬'}, 'id': 'call_0zrBaXB7tK3aMaOYhFiHXnok', 'type': 'tool_call'}]\n",
      "Calling Wikipedia tool with query: ë¼ë–¼ì˜ ì—­ì‚¬\n",
      "[AI ë‹µë³€]: ë¼ë–¼ì˜ ì—­ì‚¬ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¼ë–¼ëŠ” ì—ìŠ¤í”„ë ˆì†Œì™€ ìŠ¤íŒ€ ë°€í¬ë¥¼ ê²°í•©í•œ ìŒë£Œë¡œ, 20ì„¸ê¸° ì´ˆ ì´íƒˆë¦¬ì•„ì—ì„œ ìœ ë˜ë˜ì—ˆìŠµë‹ˆë‹¤. ë¼ë–¼ëŠ” ì»¤í”¼ ë¬¸í™”ê°€ ë°œì „í•˜ë©´ì„œ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ì–»ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ ë³€í˜•ì´ ìƒê²¨ë‚¬ìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë‹¤ë©´ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”!\n",
      "\n",
      "[Tool Call Detected]: [{'name': 'db_search_cafe_func', 'args': {'query': 'ì¹´í˜ë¼ë–¼ íŠ¹ì„±'}, 'id': 'call_8xqIeYGyenfKQq1yWDbHkz29', 'type': 'tool_call'}]\n",
      "Calling DB search tool with query: ì¹´í˜ë¼ë–¼ íŠ¹ì„±\n",
      "[AI ë‹µë³€]: ì¹´í˜ë¼ë–¼ì˜ íŠ¹ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "- **ê°€ê²©**: â‚©5,500\n",
      "- **ì£¼ìš” ì›ë£Œ**: ì—ìŠ¤í”„ë ˆì†Œ, ìŠ¤íŒ€ ë°€í¬\n",
      "- **ì„¤ëª…**: ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ë¶€ë“œëŸ½ê²Œ ìŠ¤íŒ€í•œ ìš°ìœ ë¥¼ ë„£ì–´ ë§Œë“  ëŒ€í‘œì ì¸ ë°€í¬ ì»¤í”¼ì…ë‹ˆë‹¤. í¬ë¦¬ë¯¸í•œ ì§ˆê°ê³¼ ë¶€ë“œëŸ¬ìš´ ë§›ì´ íŠ¹ì§•ì´ë©°, ë‹¤ì–‘í•œ ì‹œëŸ½ê³¼ í† í•‘ ì¶”ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë˜í•œ, ë¼ë–¼ ì•„íŠ¸ë¡œ ì‹œê°ì  ì¦ê±°ì›€ë„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "[AI ë‹µë³€]: ì²œë§Œì—ìš”! ì–¸ì œë“ ì§€ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë‹¤ì‹œ ì°¾ì•„ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸ˜Š\n",
      "AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
      "\n",
      "--- AI ì–´ì‹œìŠ¤í„´íŠ¸ ì¢…ë£Œ ---\n"
     ]
    }
   ],
   "source": [
    "# 2. ë„êµ¬ ì •ì˜\n",
    "\n",
    "# a) tavily_search_func\n",
    "tavily_search_tool = TavilySearchResults()\n",
    "\n",
    "# b) wiki_summary\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì¼ë°˜ ì§€ì‹ ê²€ìƒ‰ ë° ìš”ì•½.\n",
    "    ì…ë ¥: ê²€ìƒ‰ ì£¼ì œ (str)\n",
    "    ì¶œë ¥: ìš”ì•½ëœ ì •ë³´ (str)\n",
    "    \"\"\"\n",
    "    print(f\"Calling Wikipedia tool with query: {query}\")\n",
    "    try:\n",
    "        summary = wikipedia_wrapper.run(query)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "\n",
    "# c) db_search_cafe_func\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ë¡œì»¬ ì¹´í˜ ë©”ë‰´ DBì—ì„œ ë©”ë‰´ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰.\n",
    "    ì…ë ¥: ë©”ë‰´ ê´€ë ¨ ì¿¼ë¦¬ (str)\n",
    "    ì¶œë ¥: ê´€ë ¨ ë©”ë‰´ ì •ë³´ (str)\n",
    "    ì‚¬ìš© ì˜ˆ: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©, ì¬ë£Œ, íŠ¹ì§• ë“±\n",
    "    \"\"\"\n",
    "    print(f\"Calling DB search tool with query: {query}\")\n",
    "    docs = cafe_vector_db.similarity_search(query, k=1) # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 1ê°œ ê²€ìƒ‰\n",
    "    if docs:\n",
    "        # Document ê°ì²´ì˜ page_contentë¥¼ ë°˜í™˜\n",
    "        return docs[0].page_content\n",
    "    return \"í•´ë‹¹ ë©”ë‰´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ëª¨ë“  ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "tools = [tavily_search_tool, wiki_summary, db_search_cafe_func]\n",
    "\n",
    "# 3. LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# 4. í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "system_prompt_content = (\n",
    "    \"ë‹¹ì‹ ì€ ì¹´í˜ ë©”ë‰´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³ , í•„ìš”ì‹œ ì›¹ ê²€ìƒ‰ì´ë‚˜ ìœ„í‚¤í”¼ë””ì•„ë¥¼ í™œìš©í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "    \"ë©”ë‰´ ì •ë³´ëŠ” 'db_search_cafe_func' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³ , ì¼ë°˜ì ì¸ ì§€ì‹ì€ 'wiki_summary'ë¥¼, ìµœì‹  ì •ë³´ë‚˜ ì›¹ ê²€ìƒ‰ì€ 'tavily_search_func'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "    \"ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•  ì‹œì ì„ ì •í™•í•˜ê²Œ íŒë‹¨í•˜ê³ , ë¶ˆí•„ìš”í•œ ë„êµ¬ í˜¸ì¶œì€ ì‚¼ê°€ì„¸ìš”. ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì—ëŠ” ë°”ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# Few-shot ì˜ˆì œ ì •ì˜ (ë©”ì‹œì§€ ê°ì²´ ë¦¬ìŠ¤íŠ¸)\n",
    "# AIì˜ ToolCall í˜•ì‹ì€ LLMì´ ì‹¤ì œë¡œ ì¶œë ¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¥¼ ê°€ì •í•˜ì—¬ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "few_shot_examples = [\n",
    "    HumanMessage(content=\"ì•„ë©”ë¦¬ì¹´ë…¸ ê°€ê²© ì–¼ë§ˆì¸ê°€ìš”?\"),\n",
    "    AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"db_search_cafe_func\", \"args\": {\"query\": \"ì•„ë©”ë¦¬ì¹´ë…¸ ê°€ê²©\"}, \"id\": \"call_1\"}\n",
    "        ]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"ì•„ë©”ë¦¬ì¹´ë…¸: â‚©4,500. ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ëœ¨ê±°ìš´ ë¬¼ì„ ë”í•´ ë§Œë“  í´ë˜ì‹í•œ ë¸”ë™ ì»¤í”¼ì…ë‹ˆë‹¤.\",\n",
    "        tool_call_id=\"call_1\"\n",
    "    ),\n",
    "    AIMessage(content=\"ì•„ë©”ë¦¬ì¹´ë…¸ëŠ” â‚©4,500ì´ë©°, ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ëœ¨ê±°ìš´ ë¬¼ì„ ë”í•´ ë§Œë“  í´ë˜ì‹í•œ ë¸”ë™ ì»¤í”¼ì…ë‹ˆë‹¤.\"),\n",
    "\n",
    "    HumanMessage(content=\"ìµœì‹  ì»¤í”¼ íŠ¸ë Œë“œê°€ ê¶ê¸ˆí•´ìš”.\"),\n",
    "    AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"tavily_search_tool\", \"args\": {\"query\": \"2025ë…„ ìµœì‹  ì»¤í”¼ íŠ¸ë Œë“œ\"}, \"id\": \"call_2\"}\n",
    "        ]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"ê²€ìƒ‰ ê²°ê³¼: 2025ë…„ì—ëŠ” ì§€ì† ê°€ëŠ¥í•œ ì»¤í”¼, ì½œë“œë¸Œë£¨ì˜ ì¸ê¸° ì§€ì†, RTD(Ready To Drink) ì»¤í”¼ ì‹œì¥ ì„±ì¥ ë“±ì˜ íŠ¸ë Œë“œê°€ ì˜ˆìƒë©ë‹ˆë‹¤.\",\n",
    "        tool_call_id=\"call_2\"\n",
    "    ),\n",
    "    AIMessage(content=\"2025ë…„ ìµœì‹  ì»¤í”¼ íŠ¸ë Œë“œë¡œëŠ” ì§€ì† ê°€ëŠ¥í•œ ì»¤í”¼, ì½œë“œë¸Œë£¨ì˜ ì¸ê¸° ì§€ì†, RTD(Ready To Drink) ì»¤í”¼ ì‹œì¥ ì„±ì¥ ë“±ì´ ì˜ˆìƒë©ë‹ˆë‹¤.\"),\n",
    "    \n",
    "    HumanMessage(content=\"ì»¤í”¼ëŠ” ì–¸ì œë¶€í„° ë§ˆì‹œê¸° ì‹œì‘í–ˆë‚˜ìš”?\"),\n",
    "    AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"wiki_summary\", \"args\": {\"query\": \"ì»¤í”¼ì˜ ì—­ì‚¬\"}, \"id\": \"call_3\"}\n",
    "        ]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"ìœ„í‚¤í”¼ë””ì•„ ìš”ì•½: ì»¤í”¼ëŠ” 9ì„¸ê¸° ì—í‹°ì˜¤í”¼ì•„ì—ì„œ ì²˜ìŒ ë°œê²¬ëœ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©°, ì´í›„ ì´ìŠ¬ëŒ ì„¸ê³„ë¥¼ ê±°ì³ ìœ ëŸ½ìœ¼ë¡œ ì „íŒŒë˜ì—ˆìŠµë‹ˆë‹¤.\",\n",
    "        tool_call_id=\"call_3\"\n",
    "    ),\n",
    "    AIMessage(content=\"ì»¤í”¼ëŠ” 9ì„¸ê¸° ì—í‹°ì˜¤í”¼ì•„ì—ì„œ ì²˜ìŒ ë°œê²¬ëœ ê²ƒìœ¼ë¡œ ì¶”ì •ë˜ë©°, ì´í›„ ì´ìŠ¬ëŒ ì„¸ê³„ë¥¼ ê±°ì³ ìœ ëŸ½ìœ¼ë¡œ ì „íŒŒë˜ì—ˆìŠµë‹ˆë‹¤.\"),\n",
    "\n",
    "    HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”?\"), # ë„êµ¬ í˜¸ì¶œì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ ëŒ€í™” ì˜ˆì‹œ\n",
    "    AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì¹´í˜ ë©”ë‰´ë‚˜ ì»¤í”¼ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.\"),\n",
    "\n",
    "    HumanMessage(content=\"ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?\"), # ë„êµ¬ í˜¸ì¶œì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ ëŒ€í™” ì˜ˆì‹œ (ì•„ëŠ” ì •ë³´ê°€ ì•„ë‹˜)\n",
    "    AIMessage(content=\"ì €ëŠ” ì¹´í˜ ë©”ë‰´ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚ ì”¨ ì •ë³´ëŠ” ì œê³µí•´ ë“œë¦´ ìˆ˜ ì—†ì–´ìš”.\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_content),\n",
    "        # ì—¬ê¸°ì— Few-shot ì˜ˆì œ ë©”ì‹œì§€ë“¤ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        *few_shot_examples,\n",
    "        # ì´í›„ì—ëŠ” ì‹¤ì œ ëŒ€í™” ê¸°ë¡ê³¼ í˜„ì¬ ì‚¬ìš©ì ì…ë ¥, ì—ì´ì „íŠ¸ ìŠ¤í¬ë˜ì¹˜íŒ¨ë“œê°€ ì´ì–´ì§‘ë‹ˆë‹¤.\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. LLMì— ë„êµ¬ ë°”ì¸ë”©\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "# 6. ê°„ë‹¨í•œ ë„êµ¬ í˜¸ì¶œ ì²´ì¸ êµ¬í˜„\n",
    "@chain\n",
    "def tool_calling_chain(input_data: dict):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ LLMì´ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•˜ë©°, ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì²´ì¸.\n",
    "    \"\"\"\n",
    "    query = input_data[\"input\"]\n",
    "    chat_history = input_data.get(\"chat_history\", [])\n",
    "    \n",
    "    agent_scratchpad = [] \n",
    "\n",
    "    prompt_values = {\n",
    "        \"input\": query,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"agent_scratchpad\": agent_scratchpad\n",
    "    }\n",
    "    \n",
    "    full_prompt_message = prompt.invoke(prompt_values)\n",
    "    \n",
    "    ai_message = agent_llm.invoke(full_prompt_message)\n",
    "    \n",
    "    # Step 2: ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ í™•ì¸ ë° ì‹¤í–‰\n",
    "    if ai_message.tool_calls:\n",
    "        print(f\"\\n[Tool Call Detected]: {ai_message.tool_calls}\")\n",
    "        tool_results = []\n",
    "        for tool_call_dict in ai_message.tool_calls:\n",
    "            tool_name = tool_call_dict.get('name') \n",
    "            tool_args = tool_call_dict.get('args')\n",
    "            tool_id = tool_call_dict.get('id')\n",
    "\n",
    "            if not tool_name:\n",
    "                print(f\"Warning: Tool call dictionary missing 'name' key: {tool_call_dict}. Skipping this tool call.\")\n",
    "                continue\n",
    "\n",
    "            result = None\n",
    "            try:\n",
    "                if tool_name == tavily_search_tool.name:\n",
    "                    result = tavily_search_tool.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == wiki_summary.name:\n",
    "                    result = wiki_summary.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == db_search_cafe_func.name:\n",
    "                    result = db_search_cafe_func.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                else:\n",
    "                    result = f\"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}\"\n",
    "            except Exception as e:\n",
    "                result = f\"ë„êµ¬ {tool_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "            \n",
    "            tool_results.append(ToolMessage(content=str(result), tool_call_id=tool_id))\n",
    "        \n",
    "        # Step 3: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ LLM ì¬í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "        updated_agent_scratchpad = [ai_message] + tool_results\n",
    "\n",
    "        re_invoke_prompt_values = {\n",
    "            \"input\": query,\n",
    "            \"chat_history\": chat_history,\n",
    "            \"agent_scratchpad\": updated_agent_scratchpad\n",
    "        }\n",
    "        \n",
    "        re_invoke_full_prompt_message = prompt.invoke(re_invoke_prompt_values)\n",
    "        \n",
    "        final_response_message = agent_llm.invoke(re_invoke_full_prompt_message)\n",
    "        return final_response_message.content\n",
    "    else:\n",
    "        # ë„êµ¬ í˜¸ì¶œì´ ì—†ëŠ” ê²½ìš° LLMì˜ ì›ë˜ ë‹µë³€ ë°˜í™˜\n",
    "        return ai_message.content\n",
    "\n",
    "# 7. ì„¸ì…˜ ê¸°ë¡ ê´€ë¦¬ ë° RunnableWithMessageHistory ë°”ì¸ë”©\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    tool_calling_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 8. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬ (ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ë³€ê²½)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- ì¹´í˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥) ---\")\n",
    "\n",
    "    session_id = \"user_session_fewshot_1\" # Few-shot í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìƒˆ ì„¸ì…˜ ID\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n[ë‹¹ì‹ ì˜ ì§ˆë¬¸]: \")\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"ì¢…ë£Œ\"]:\n",
    "            print(\"AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = conversational_chain.invoke(\n",
    "                {\"input\": user_input},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            print(f\"[AI ë‹µë³€]: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ì˜¤ë¥˜ ë°œìƒ]: {e}\")\n",
    "            print(\"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ì§ˆë¬¸ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹œì‘í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\")\n",
    "\n",
    "    print(\"\\n--- AI ì–´ì‹œìŠ¤í„´íŠ¸ ì¢…ë£Œ ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
