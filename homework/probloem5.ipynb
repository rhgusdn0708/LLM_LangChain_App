{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbce5a03",
   "metadata": {},
   "source": [
    "### 5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e56483e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "import re\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5f1a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./db/cafe_db' 경로에서 FAISS 벡터 DB 로드 중...\n",
      "FAISS 벡터 DB 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 벡터 DB 로드\n",
    "def load_vector_db(db_path=\"./db/cafe_db\"):\n",
    "    \"\"\"\n",
    "    저장된 FAISS 벡터 데이터베이스를 로드합니다.\n",
    "    \"\"\"\n",
    "    print(f\"'{db_path}' 경로에서 FAISS 벡터 DB 로드 중...\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS 벡터 DB 로드 완료.\")\n",
    "    return vectorstore\n",
    "\n",
    "# 벡터 DB 인스턴스 로드 (전역적으로 사용)\n",
    "cafe_vector_db = load_vector_db()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ec619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 카페 AI 어시스턴트 시작 (종료하려면 'exit' 또는 'quit' 입력) ---\n",
      "\n",
      "[사용자 질문]: 아메리카노의 가격은 얼마야?\n",
      "\n",
      "[Tool Call Detected]: [{'name': 'db_search_cafe_func', 'args': {'query': '아메리카노 가격'}, 'id': 'call_3lNCQyZVz9niH7jAJYQJZHJx', 'type': 'tool_call'}]\n",
      "Calling DB search tool with query: 아메리카노 가격\n",
      "[AI 답변]: 아메리카노의 가격은 ₩4,500입니다. 이 음료는 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피로, 원두 본연의 맛을 잘 느낄 수 있으며 깔끔하고 깊은 풍미가 특징입니다. 필요에 따라 설탕이나 시럽을 추가할 수 있습니다.\n",
      "\n",
      "[사용자 질문]: 고마워 끝!\n",
      "[AI 답변]: 천만에요! 궁금한 점이 있으면 언제든지 말씀해 주세요. 좋은 하루 되세요! 😊\n",
      "AI 어시스턴트를 종료합니다.\n",
      "\n",
      "--- AI 어시스턴트 종료 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. 도구 정의\n",
    "\n",
    "# a) tavily_search_func\n",
    "tavily_search_tool = TavilySearchResults()\n",
    "\n",
    "# b) wiki_summary\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"\n",
    "    위키피디아에서 일반 지식 검색 및 요약.\n",
    "    입력: 검색 주제 (str)\n",
    "    출력: 요약된 정보 (str)\n",
    "    \"\"\"\n",
    "    print(f\"Calling Wikipedia tool with query: {query}\")\n",
    "    try:\n",
    "        summary = wikipedia_wrapper.run(query)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"위키피디아 검색 중 오류 발생: {e}\"\n",
    "\n",
    "# c) db_search_cafe_func\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"\n",
    "    로컬 카페 메뉴 DB에서 메뉴 관련 정보 검색.\n",
    "    입력: 메뉴 관련 쿼리 (str)\n",
    "    출력: 관련 메뉴 정보 (str)\n",
    "    사용 예: 아메리카노의 가격, 재료, 특징 등\n",
    "    \"\"\"\n",
    "    print(f\"Calling DB search tool with query: {query}\")\n",
    "    docs = cafe_vector_db.similarity_search(query, k=1) # 가장 유사한 문서 1개 검색\n",
    "    if docs:\n",
    "        # Document 객체의 page_content를 반환\n",
    "        return docs[0].page_content\n",
    "    return \"해당 메뉴에 대한 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "# 모든 도구 리스트\n",
    "tools = [tavily_search_tool, wiki_summary, db_search_cafe_func]\n",
    "\n",
    "# 3. LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# 4. 프롬프트 정의\n",
    "system_prompt_content = (\n",
    "    \"당신은 카페 메뉴에 대한 질문에 답변하고, 필요시 웹 검색이나 위키피디아를 활용하는 친절한 AI 어시스턴트입니다.\"\n",
    "    \"메뉴 정보는 'db_search_cafe_func' 도구를 사용하고, 일반적인 지식은 'wiki_summary'를, 최신 정보나 웹 검색은 'tavily_search_func'를 사용하세요.\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_content),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. LLM에 도구 바인딩\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "# 6. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def tool_calling_chain(input_data: dict):\n",
    "    \"\"\"\n",
    "    사용자 질문을 받아 LLM이 도구를 선택하고 실행하며, 결과를 종합하여 최종 답변을 생성하는 체인.\n",
    "    \"\"\"\n",
    "    query = input_data[\"input\"]\n",
    "    chat_history = input_data.get(\"chat_history\", [])\n",
    "    \n",
    "    agent_scratchpad = [] \n",
    "\n",
    "    prompt_values = {\n",
    "        \"input\": query,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"agent_scratchpad\": agent_scratchpad\n",
    "    }\n",
    "    \n",
    "    full_prompt_message = prompt.invoke(prompt_values)\n",
    "    \n",
    "    ai_message = agent_llm.invoke(full_prompt_message)\n",
    "    \n",
    "    # Step 2: 도구 호출 결과 확인 및 실행\n",
    "    # 여기가 수정된 부분입니다: tool_call_dict로 접근하도록 변경\n",
    "    if ai_message.tool_calls:\n",
    "        print(f\"\\n[Tool Call Detected]: {ai_message.tool_calls}\")\n",
    "        tool_results = []\n",
    "        for tool_call_dict in ai_message.tool_calls: # tool_call_dict로 이름 변경\n",
    "            # dict 객체에서 'name', 'args', 'id' 키로 접근\n",
    "            tool_name = tool_call_dict.get('name') \n",
    "            tool_args = tool_call_dict.get('args')\n",
    "            tool_id = tool_call_dict.get('id')\n",
    "\n",
    "            if not tool_name: # 'name' 키가 없는 경우를 대비 (예외 처리)\n",
    "                print(f\"Warning: Tool call dictionary missing 'name' key: {tool_call_dict}. Skipping this tool call.\")\n",
    "                continue\n",
    "\n",
    "            result = None\n",
    "            try:\n",
    "                if tool_name == tavily_search_tool.name:\n",
    "                    # tool_args가 None일 수 있으므로 .get('query') 호출 시 기본값 지정\n",
    "                    result = tavily_search_tool.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == wiki_summary.name:\n",
    "                    result = wiki_summary.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == db_search_cafe_func.name:\n",
    "                    result = db_search_cafe_func.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                else:\n",
    "                    result = f\"알 수 없는 도구: {tool_name}\"\n",
    "            except Exception as e:\n",
    "                result = f\"도구 {tool_name} 실행 중 오류 발생: {e}\"\n",
    "            \n",
    "            # ToolMessage 생성 시 tool_id를 전달\n",
    "            tool_results.append(ToolMessage(content=str(result), tool_call_id=tool_id))\n",
    "        \n",
    "        # Step 3: 도구 실행 결과를 포함하여 LLM 재호출하여 최종 답변 생성\n",
    "        updated_agent_scratchpad = [ai_message] + tool_results\n",
    "\n",
    "        re_invoke_prompt_values = {\n",
    "            \"input\": query,\n",
    "            \"chat_history\": chat_history,\n",
    "            \"agent_scratchpad\": updated_agent_scratchpad\n",
    "        }\n",
    "        \n",
    "        re_invoke_full_prompt_message = prompt.invoke(re_invoke_prompt_values)\n",
    "        \n",
    "        final_response_message = agent_llm.invoke(re_invoke_full_prompt_message)\n",
    "        return final_response_message.content\n",
    "    else:\n",
    "        # 도구 호출이 없는 경우 LLM의 원래 답변 반환\n",
    "        return ai_message.content\n",
    "\n",
    "# 7. 세션 기록 관리 및 RunnableWithMessageHistory 바인딩\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    tool_calling_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 8. 테스트 질문 처리\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- 카페 AI 어시스턴트 시작 (종료하려면 'exit' 또는 'quit' 입력) ---\")\n",
    "\n",
    "    # 세션 ID를 하나로 유지하여 이전 대화 기록을 활용하도록 설정 (선택 사항)\n",
    "    session_id = \"user_session_123\" \n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n당신의 질문을 입력하세요: \")\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"종료\"]:\n",
    "            print(\"AI 어시스턴트를 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n[사용자 질문]: {user_input}\")\n",
    "        \n",
    "        try:\n",
    "            response = conversational_chain.invoke(\n",
    "                {\"input\": user_input},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            print(f\"[AI 답변]: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[오류 발생]: {e}\")\n",
    "            print(\"오류가 발생하여 질문 처리를 중단합니다. 관리자에게 문의하세요.\")\n",
    "            # 오류 발생 시 루프를 종료하거나 계속 진행할지 선택할 수 있습니다.\n",
    "            # 여기서는 오류가 나더라도 계속 질문을 받을 수 있도록 break를 제거합니다.\n",
    "\n",
    "    print(\"\\n--- AI 어시스턴트 종료 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d9259",
   "metadata": {},
   "source": [
    "### 5-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71a56b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "import re\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79aa73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./db/cafe_db' 경로에서 FAISS 벡터 DB 로드 중...\n",
      "FAISS 벡터 DB 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. 벡터 DB 로드\n",
    "def load_vector_db(db_path=\"./db/cafe_db\"):\n",
    "    \"\"\"\n",
    "    저장된 FAISS 벡터 데이터베이스를 로드합니다.\n",
    "    \"\"\"\n",
    "    print(f\"'{db_path}' 경로에서 FAISS 벡터 DB 로드 중...\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS 벡터 DB 로드 완료.\")\n",
    "    return vectorstore\n",
    "\n",
    "# 벡터 DB 인스턴스 로드 (전역적으로 사용)\n",
    "cafe_vector_db = load_vector_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f799f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 카페 AI 어시스턴트 시작 (종료하려면 'exit' 또는 'quit' 입력) ---\n",
      "\n",
      "[Tool Call Detected]: [{'name': 'wiki_summary', 'args': {'query': '라떼의 역사'}, 'id': 'call_0zrBaXB7tK3aMaOYhFiHXnok', 'type': 'tool_call'}]\n",
      "Calling Wikipedia tool with query: 라떼의 역사\n",
      "[AI 답변]: 라떼의 역사에 대한 구체적인 정보를 찾지 못했습니다. 하지만 일반적으로 라떼는 에스프레소와 스팀 밀크를 결합한 음료로, 20세기 초 이탈리아에서 유래되었습니다. 라떼는 커피 문화가 발전하면서 전 세계적으로 인기를 얻었으며, 다양한 변형이 생겨났습니다. 더 자세한 정보가 필요하시다면 다른 질문을 해주세요!\n",
      "\n",
      "[Tool Call Detected]: [{'name': 'db_search_cafe_func', 'args': {'query': '카페라떼 특성'}, 'id': 'call_8xqIeYGyenfKQq1yWDbHkz29', 'type': 'tool_call'}]\n",
      "Calling DB search tool with query: 카페라떼 특성\n",
      "[AI 답변]: 카페라떼의 특성은 다음과 같습니다:\n",
      "\n",
      "- **가격**: ₩5,500\n",
      "- **주요 원료**: 에스프레소, 스팀 밀크\n",
      "- **설명**: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질감과 부드러운 맛이 특징이며, 다양한 시럽과 토핑 추가가 가능합니다. 또한, 라떼 아트로 시각적 즐거움도 제공합니다.\n",
      "[AI 답변]: 천만에요! 언제든지 궁금한 점이 있으면 다시 찾아주세요. 좋은 하루 되세요! 😊\n",
      "AI 어시스턴트를 종료합니다.\n",
      "\n",
      "--- AI 어시스턴트 종료 ---\n"
     ]
    }
   ],
   "source": [
    "# 2. 도구 정의\n",
    "\n",
    "# a) tavily_search_func\n",
    "tavily_search_tool = TavilySearchResults()\n",
    "\n",
    "# b) wiki_summary\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"\n",
    "    위키피디아에서 일반 지식 검색 및 요약.\n",
    "    입력: 검색 주제 (str)\n",
    "    출력: 요약된 정보 (str)\n",
    "    \"\"\"\n",
    "    print(f\"Calling Wikipedia tool with query: {query}\")\n",
    "    try:\n",
    "        summary = wikipedia_wrapper.run(query)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"위키피디아 검색 중 오류 발생: {e}\"\n",
    "\n",
    "# c) db_search_cafe_func\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"\n",
    "    로컬 카페 메뉴 DB에서 메뉴 관련 정보 검색.\n",
    "    입력: 메뉴 관련 쿼리 (str)\n",
    "    출력: 관련 메뉴 정보 (str)\n",
    "    사용 예: 아메리카노의 가격, 재료, 특징 등\n",
    "    \"\"\"\n",
    "    print(f\"Calling DB search tool with query: {query}\")\n",
    "    docs = cafe_vector_db.similarity_search(query, k=1) # 가장 유사한 문서 1개 검색\n",
    "    if docs:\n",
    "        # Document 객체의 page_content를 반환\n",
    "        return docs[0].page_content\n",
    "    return \"해당 메뉴에 대한 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "# 모든 도구 리스트\n",
    "tools = [tavily_search_tool, wiki_summary, db_search_cafe_func]\n",
    "\n",
    "# 3. LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# 4. 프롬프트 정의\n",
    "system_prompt_content = (\n",
    "    \"당신은 카페 메뉴에 대한 질문에 답변하고, 필요시 웹 검색이나 위키피디아를 활용하는 친절한 AI 어시스턴트입니다.\"\n",
    "    \"메뉴 정보는 'db_search_cafe_func' 도구를 사용하고, 일반적인 지식은 'wiki_summary'를, 최신 정보나 웹 검색은 'tavily_search_func'를 사용하세요.\"\n",
    "    \"도구를 사용해야 할 시점을 정확하게 판단하고, 불필요한 도구 호출은 삼가세요. 도구를 사용하지 않고 답변할 수 있는 질문에는 바로 답변하세요.\"\n",
    ")\n",
    "\n",
    "# Few-shot 예제 정의 (메시지 객체 리스트)\n",
    "# AI의 ToolCall 형식은 LLM이 실제로 출력하는 딕셔너리 형태를 가정하여 작성했습니다.\n",
    "few_shot_examples = [\n",
    "    HumanMessage(content=\"아메리카노 가격 얼마인가요?\"),\n",
    "    AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"db_search_cafe_func\", \"args\": {\"query\": \"아메리카노 가격\"}, \"id\": \"call_1\"}\n",
    "        ]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"아메리카노: ₩4,500. 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다.\",\n",
    "        tool_call_id=\"call_1\"\n",
    "    ),\n",
    "    AIMessage(content=\"아메리카노는 ₩4,500이며, 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다.\"),\n",
    "\n",
    "    HumanMessage(content=\"최신 커피 트렌드가 궁금해요.\"),\n",
    "    AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"tavily_search_tool\", \"args\": {\"query\": \"2025년 최신 커피 트렌드\"}, \"id\": \"call_2\"}\n",
    "        ]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"검색 결과: 2025년에는 지속 가능한 커피, 콜드브루의 인기 지속, RTD(Ready To Drink) 커피 시장 성장 등의 트렌드가 예상됩니다.\",\n",
    "        tool_call_id=\"call_2\"\n",
    "    ),\n",
    "    AIMessage(content=\"2025년 최신 커피 트렌드로는 지속 가능한 커피, 콜드브루의 인기 지속, RTD(Ready To Drink) 커피 시장 성장 등이 예상됩니다.\"),\n",
    "    \n",
    "    HumanMessage(content=\"커피는 언제부터 마시기 시작했나요?\"),\n",
    "    AIMessage(\n",
    "        content=\"\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"wiki_summary\", \"args\": {\"query\": \"커피의 역사\"}, \"id\": \"call_3\"}\n",
    "        ]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"위키피디아 요약: 커피는 9세기 에티오피아에서 처음 발견된 것으로 추정되며, 이후 이슬람 세계를 거쳐 유럽으로 전파되었습니다.\",\n",
    "        tool_call_id=\"call_3\"\n",
    "    ),\n",
    "    AIMessage(content=\"커피는 9세기 에티오피아에서 처음 발견된 것으로 추정되며, 이후 이슬람 세계를 거쳐 유럽으로 전파되었습니다.\"),\n",
    "\n",
    "    HumanMessage(content=\"안녕하세요?\"), # 도구 호출이 필요 없는 일반 대화 예시\n",
    "    AIMessage(content=\"안녕하세요! 궁금한 카페 메뉴나 커피에 대해 무엇이든 물어보세요.\"),\n",
    "\n",
    "    HumanMessage(content=\"오늘 날씨는 어떤가요?\"), # 도구 호출이 필요 없는 일반 대화 예시 (아는 정보가 아님)\n",
    "    AIMessage(content=\"저는 카페 메뉴와 관련된 질문에 답변해 드릴 수 있습니다. 날씨 정보는 제공해 드릴 수 없어요.\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_content),\n",
    "        # 여기에 Few-shot 예제 메시지들을 추가합니다.\n",
    "        *few_shot_examples,\n",
    "        # 이후에는 실제 대화 기록과 현재 사용자 입력, 에이전트 스크래치패드가 이어집니다.\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. LLM에 도구 바인딩\n",
    "agent_llm = llm.bind_tools(tools)\n",
    "\n",
    "# 6. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def tool_calling_chain(input_data: dict):\n",
    "    \"\"\"\n",
    "    사용자 질문을 받아 LLM이 도구를 선택하고 실행하며, 결과를 종합하여 최종 답변을 생성하는 체인.\n",
    "    \"\"\"\n",
    "    query = input_data[\"input\"]\n",
    "    chat_history = input_data.get(\"chat_history\", [])\n",
    "    \n",
    "    agent_scratchpad = [] \n",
    "\n",
    "    prompt_values = {\n",
    "        \"input\": query,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"agent_scratchpad\": agent_scratchpad\n",
    "    }\n",
    "    \n",
    "    full_prompt_message = prompt.invoke(prompt_values)\n",
    "    \n",
    "    ai_message = agent_llm.invoke(full_prompt_message)\n",
    "    \n",
    "    # Step 2: 도구 호출 결과 확인 및 실행\n",
    "    if ai_message.tool_calls:\n",
    "        print(f\"\\n[Tool Call Detected]: {ai_message.tool_calls}\")\n",
    "        tool_results = []\n",
    "        for tool_call_dict in ai_message.tool_calls:\n",
    "            tool_name = tool_call_dict.get('name') \n",
    "            tool_args = tool_call_dict.get('args')\n",
    "            tool_id = tool_call_dict.get('id')\n",
    "\n",
    "            if not tool_name:\n",
    "                print(f\"Warning: Tool call dictionary missing 'name' key: {tool_call_dict}. Skipping this tool call.\")\n",
    "                continue\n",
    "\n",
    "            result = None\n",
    "            try:\n",
    "                if tool_name == tavily_search_tool.name:\n",
    "                    result = tavily_search_tool.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == wiki_summary.name:\n",
    "                    result = wiki_summary.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                elif tool_name == db_search_cafe_func.name:\n",
    "                    result = db_search_cafe_func.invoke(tool_args.get(\"query\") if tool_args else \"\")\n",
    "                else:\n",
    "                    result = f\"알 수 없는 도구: {tool_name}\"\n",
    "            except Exception as e:\n",
    "                result = f\"도구 {tool_name} 실행 중 오류 발생: {e}\"\n",
    "            \n",
    "            tool_results.append(ToolMessage(content=str(result), tool_call_id=tool_id))\n",
    "        \n",
    "        # Step 3: 도구 실행 결과를 포함하여 LLM 재호출하여 최종 답변 생성\n",
    "        updated_agent_scratchpad = [ai_message] + tool_results\n",
    "\n",
    "        re_invoke_prompt_values = {\n",
    "            \"input\": query,\n",
    "            \"chat_history\": chat_history,\n",
    "            \"agent_scratchpad\": updated_agent_scratchpad\n",
    "        }\n",
    "        \n",
    "        re_invoke_full_prompt_message = prompt.invoke(re_invoke_prompt_values)\n",
    "        \n",
    "        final_response_message = agent_llm.invoke(re_invoke_full_prompt_message)\n",
    "        return final_response_message.content\n",
    "    else:\n",
    "        # 도구 호출이 없는 경우 LLM의 원래 답변 반환\n",
    "        return ai_message.content\n",
    "\n",
    "# 7. 세션 기록 관리 및 RunnableWithMessageHistory 바인딩\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    tool_calling_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 8. 테스트 질문 처리 (사용자 입력으로 변경)\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- 카페 AI 어시스턴트 시작 (종료하려면 'exit' 또는 'quit' 입력) ---\")\n",
    "\n",
    "    session_id = \"user_session_fewshot_1\" # Few-shot 테스트를 위한 새 세션 ID\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n[당신의 질문]: \")\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"종료\"]:\n",
    "            print(\"AI 어시스턴트를 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = conversational_chain.invoke(\n",
    "                {\"input\": user_input},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "            print(f\"[AI 답변]: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[오류 발생]: {e}\")\n",
    "            print(\"오류가 발생하여 질문 처리를 중단할 수 있습니다. 스크립트를 다시 시작하거나 관리자에게 문의하세요.\")\n",
    "\n",
    "    print(\"\\n--- AI 어시스턴트 종료 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
